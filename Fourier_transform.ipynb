{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Transformata Fouriera dla obrazów cyfrowych. Filtracja w dziedzinie częstotliwości."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cel ćwiczenia\n",
    "\n",
    "- Zapoznanie z wykorzystaniem transformaty Fouriera w przetwarzaniu obrazów cyfrowych.\n",
    "- Zapoznanie z pojęciem F-obrazu (amplitudy i fazy).\n",
    "- Zapoznanie z własnościami transformaty Fouriera.\n",
    "- Zapoznanie z filtracją w dziedzinie częstotliwości.\n",
    "\n",
    "Na jednym z poprzednich ćwiczeń zetknęliśmy się z pojęciem konwolucji.\n",
    "Przykładem może być filtracja dolno i górnoprzepustowa.\n",
    "Operacja ta odpowiada mnożeniu w dziedzinie częstotliwości zgodnie z zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{F}(g(x,y)*h(x,y)) = \\mathcal{F}(g(x,y)) \\cdot \\mathcal{F}(h(x,y))\n",
    "\\end{equation}\n",
    "\n",
    "gdzie: $\\mathcal{F}$ oznacza transformatę Fouriera, a $*$ jest splotem.\n",
    "\n",
    "Operacja filtracji w dziedzinie częstotliwości może okazać się bardziej efektywna, jeżeli operacje $fft$ i $ifft$ (odpowiednio szybka transformata Fouriera -- *fast Fourier transform* -- oraz odwrotna szybka transformata Fouriera -- *inverse fast Fourier transform*) zajmą mniej czasu niż klasyczna konwolucja (zazwyczaj ma to miejsce dla dużego obrazu, z dużą maską).\n",
    "\n",
    "Sama filtracja w dziedzinie częstotliwości to mnożenie punktowe całego obrazu przez jedną maskę.\n",
    "\n",
    "W przypadku filtracji w dziedzinie częstotliwości zakłada się, że obraz \"zawija się\" na brzegach, co może powodować pewne artefakty (zostanie to pokazane w trakcie ćwiczenia).\n",
    "\n",
    "W dziedzinie częstotliwości \"działają\" tylko filtry liniowe.\n",
    "Filtry medianowe, maksymalne, minimalne itp. nie mają swoich odpowiedników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dwuwymiarowa transformata Fouriera\n",
    "\n",
    "1. Wczytaj plik \"dwieFale.bmp\" w skali szarości.\n",
    "Jest to obraz powstały na podstawie następującej zależności:\n",
    "\n",
    "\\begin{equation}\n",
    "L(m, n) = 128 + 127 \\cdot \\cos(\\frac{2\\pi m}{32}+\\frac{3\\pi}{4}) \\cdot \\cos(\\frac{2\\pi n}{8}-\\frac{\\pi}{2})\n",
    "\\end{equation}<br>\n",
    "\n",
    "gdzie: $m$ i $n$ są odpowiednio numerami wierszy i kolumn.\n",
    "\n",
    "2. Do realizacji dwuwymiarowej transformaty Fouriera służy funkcja `cv2.dft`.\n",
    "Ustaw flagę `flags=cv2.DFT_COMPLEX_OUTPUT`.\n",
    "Wykonaj transformatę na wczytanym obrazie.\n",
    "W ten sposób uzyskuje się tzw. F-obraz.\n",
    "\n",
    "3. Najniższe częstotliwości znajdują się w lewym-górnym rogu obrazu.\n",
    "Dla celów wizualizacji (ale też przetwarzania) często wykonuje się tzw. przesunięcie F-obrazu, które powoduje, że niskie częstotliwości przesuwane są do środka obrazu.\n",
    "Wykorzystaj funkcję `np.fft.fftshift`.\n",
    "Jako pierwszy argument podaj wynik transformaty Fouriera.\n",
    "Jako drugi argument podaj numery osi, wzdłuż których należy wykonać operację.\n",
    "Pierwsza oś odnosi się do wierszy obrazu.\n",
    "Druga oś odnosi się do kolumn obrazu.\n",
    "Trzecia oś to część rzeczywista (`[:, :, 0]`) lub urojona (`[:, :, 1]`).\n",
    "W naszym przypadku argument powinien wyglądać tak `[0,1]`.\n",
    "\n",
    "4. Wyświetl wynik transformaty.\n",
    "Na wspólnym wykresie umieść obraz oryginalny, amplitudę i fazę F-obrazu.\n",
    "Amplitudę i fazę wyznacz za pomocą funkcji `cv2.cartToPolar`.\n",
    "Pierwszym argumentem funkcji jest część rzeczywista wyniku, a drugim urojona.\n",
    "Uwaga. W razie wątpliwości proszę sprawdzić rozmiary rezultatu transformaty Fouriera oraz przesunięcia.\n",
    "\n",
    "5. Dla wizualizacji oblicz logarytm dziesiętny amplitudy: `ALog = np.log10(A + 1)`.\n",
    "Wyświetl go zamiast amplitudy na poprzednim wykresie.\n",
    "\n",
    "6. Wczytaj obrazy *kolo.bmp*, *kwadrat.bmp*, *kwadrat45.bmp*, *trojkat.bmp*.\n",
    "Czy analizując F-obraz można coś powiedzieć o kierunku krawędzi obiektów?\n",
    "\n",
    "7. Sprawdź (empirycznie) poprawność stwierdzenia:\n",
    ">Dwuwymiarowa transformata Fouriera jest złożeniem dwóch transformat jednowymiarowych (wykonanych np. najpierw wierszowo, a później kolumnowo). Jednowymiarowa transformata realizowana jest za pomocą funkcji fft (z bibloteki Numpy).\n",
    ">\n",
    "Wykonaj najpierw transformatę po wierszach: `FRow = np.fft.fft(I, axis=0)`.\n",
    "Następnie po kolumnach: `FCol = np.fft.fft(I, axis=1)`.\n",
    "Porównaj tak uzyskany wynik z rezultatem działania funkcji `cv2.dft`.\n",
    "Można to zrobić wizualnie lub z wykorzystaniem funkcji `cv2.absdiff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Zadanie 1 - wyświetlanie\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Load required files\n",
    "if not os.path.exists(\"dwieFale.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/dwieFale.bmp\n",
    "if not os.path.exists(\"kolo.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/kolo.bmp\n",
    "if not os.path.exists(\"kwadrat.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/kwadrat.bmp\n",
    "if not os.path.exists(\"kwadrat45.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/kwadrat45.bmp\n",
    "if not os.path.exists(\"kwadratKL.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/kwadratKL.bmp\n",
    "if not os.path.exists(\"kwadratS.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/kwadratS.bmp\n",
    "if not os.path.exists(\"kwadratT.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/kwadratT.bmp\n",
    "if not os.path.exists(\"lena.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/lena.bmp\n",
    "if not os.path.exists(\"trojkat.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/trojkat.bmp\n",
    "        \n",
    "I_Fale = cv2.imread('dwieFale.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "F_fale = cv2.dft(np.float32(I_Fale), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "dft_shift = np.fft.fftshift(F_fale, [0,1])\n",
    "mag, ang = cv2.cartToPolar(dft_shift[..., 0], dft_shift[..., 1])\n",
    "Alog = np.log10(mag + 1)\n",
    "\n",
    "\n",
    "figFale, axsFale = plt.subplots(1, 3, figsize=(15,15))\n",
    "axsFale[0].imshow(I_Fale, cmap = 'gray')\n",
    "axsFale[0].axis('off')\n",
    "axsFale[1].imshow(mag, cmap = 'gray')\n",
    "axsFale[1].axis('off')\n",
    "axsFale[2].imshow(ang, cmap = 'gray')\n",
    "axsFale[2].axis('off')\n",
    "figFale.show()\n",
    "figFale, axsFale = plt.subplots(1, 3, figsize=(15,15))\n",
    "axsFale[0].imshow(I_Fale, cmap = 'gray')\n",
    "axsFale[0].axis('off')\n",
    "axsFale[1].imshow(Alog, cmap = 'gray')\n",
    "axsFale[1].axis('off')\n",
    "axsFale[2].imshow(ang, cmap = 'gray')\n",
    "axsFale[2].axis('off')\n",
    "figFale.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trojkat = cv2.imread('trojkat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "FRow = np.fft.fft(trojkat, axis=0)\n",
    "fft =  np.fft.fft(FRow, axis=1)\n",
    "dft_shift = np.fft.fftshift(fft, [0,1])\n",
    "mag, ang = cv2.cartToPolar(dft_shift[..., 0], dft_shift[..., 1])\n",
    "Alog = np.log10(mag + 1)\n",
    "figFale, axsFale = plt.subplots(1, 3, figsize=(15,15))\n",
    "axsFale[0].imshow(image, cmap = 'gray')\n",
    "axsFale[0].axis('off')\n",
    "axsFale[1].imshow(Alog, cmap = 'gray')\n",
    "axsFale[1].axis('off')\n",
    "axsFale[2].imshow(ang, cmap = 'gray')\n",
    "axsFale[2].axis('off')\n",
    "figFale.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Zadanie 1 - FFT2\n"
    }
   },
   "outputs": [],
   "source": [
    "kolo = cv2.imread('kolo.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "kwadrat = cv2.imread('kwadrat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "kwadrat45 = cv2.imread('kwadrat45.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "trojkat = cv2.imread('trojkat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def dft(image):\n",
    "    dft = cv2.dft(np.float32(image), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft, [0,1])\n",
    "    mag, ang = cv2.cartToPolar(dft_shift[..., 0], dft_shift[..., 1])\n",
    "    Alog = np.log10(mag + 1)\n",
    "    figFale, axsFale = plt.subplots(1, 3, figsize=(15,15))\n",
    "    axsFale[0].imshow(image, cmap = 'gray')\n",
    "    axsFale[0].axis('off')\n",
    "    axsFale[1].imshow(Alog, cmap = 'gray')\n",
    "    axsFale[1].axis('off')\n",
    "    axsFale[2].imshow(ang, cmap = 'gray')\n",
    "    axsFale[2].axis('off')\n",
    "    figFale.show()\n",
    "dft(kolo)\n",
    "dft(kwadrat)\n",
    "dft(kwadrat45)\n",
    "dft(trojkat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Własności dwuwymiarowej transformaty Fouriera\n",
    "\n",
    "1. Zbadaj jak zmienia się F-obraz (amplituda i faza) podczas następujących operacji: translacja, rotacja, zmiana rozmiaru, kombinacja liniowa.\n",
    "Wykorzystaj stworzony wcześniej kod.\n",
    "Uwaga. Należy użyć przygotowanych obrazów, a nie \"generować\" własne.\n",
    "2. Do badania translacji wykorzystaj obrazy *kwadrat.bmp* i *kwadratT.bmp*.\n",
    "3. Przy badaniu rotacji wykorzystaj obrazy *kwadrat.bmp* i *kwadrat45.bmp*.\n",
    "4. Przy badaniu zmiany rozmiaru wykorzystaj obrazy *kwadrat.bmp* i *kwadratS.bmp*.\n",
    "5. Przy badaniu kombinacji liniowej wykorzystaj obrazy *kwadrat.bmp*, *kwadrat45.bmp* i *kwadratKL.bmp*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Zadanie 2 - własności\n"
    }
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "\n",
    "kwadrat = cv2.imread('kwadrat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "kwadrat45 = cv2.imread('kwadrat45.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "kwadratT = cv2.imread('kwadratT.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "kwadratS = cv2.imread('kwadratS.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "kwadratKL = cv2.imread('kwadratKL.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "def translation(image):\n",
    "    h, w = image.shape[:2] \n",
    "    qh, qw = h / 4, w / 4\n",
    "    T = np.float32([[1, 0, qw], [0, 1, qh]]) \n",
    "    translated = cv2.warpAffine(image, T, (w, h))\n",
    "    return translated\n",
    "\n",
    "def rotation(image, a = 45):\n",
    "    rotated = imutils.rotate(image, angle= a)\n",
    "    return rotated\n",
    "\n",
    "def resize(image, scale = 50):\n",
    "    w_scale = int(image.shape[1] * scale / 100)\n",
    "    h_scale = int(image.shape[0] * scale / 100)\n",
    "    dsize = (w_scale, h_scale)\n",
    "    resized = cv2.resize(image, dsize)\n",
    "    \n",
    "    return resized\n",
    "\n",
    "def linear_comb(image1, image2, image3, alpha = 1, beta = 1, theta = 1):\n",
    "    result = alpha * image1 + beta * image2 + theta * image3\n",
    "    result = np.around(result).astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "dft(translation(kwadrat))\n",
    "dft(translation(kwadratT))\n",
    "\n",
    "dft(rotation(kwadrat))\n",
    "dft(rotation(kwadrat45))\n",
    "\n",
    "dft(resize(kwadrat))\n",
    "dft(resize(kwadratS))\n",
    "\n",
    "dft(linear_comb(kwadrat, kwadrat45, kwadratKL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Odwrotna dwuwymiarowa transformata Fouriera\n",
    "\n",
    "1. Wykorzystaj stworzony wcześniej kod. Wybierz dowolny obraz np \"kolo.bmp\".\n",
    "2. Przed realizacją odwrotnego przekszałcenia należy wykonać odwrotne przesunięcie.\n",
    "Wykorzystaj funkcję `np.fft.ifftshift`.\n",
    "Pierwszym argumentem jest wynik transformaty Fouriera.\n",
    "Drugim argumentem są numery osi, wzdłuż których należy wykonać operację.\n",
    "3. Wykonaj odwrotną transformatę Fouriera za pomocą funkcji `cv2.idft`.\n",
    "4. Wyświetl wynik.\n",
    "Sprawdź (wizualnie i poprzez odjęcie) czy obraz oryginalny i po przekształceniach są takie same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Zadanie 3 - odwrotna\n"
    }
   },
   "outputs": [],
   "source": [
    "def idft(image):\n",
    "    dft = cv2.dft(np.float32(image), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft, [0,1])\n",
    "    idft_shift = np.fft.ifftshift(dft_shift, [0,1])\n",
    "    idft = cv2.idft(idft_shift)\n",
    "    idft = cv2.magnitude(idft[:,:,0],idft[:,:,1])\n",
    "    idft = cv2.normalize(idft, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n",
    "    axs[0].imshow(image, cmap = 'gray')\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title('orginal')\n",
    "    axs[1].imshow(idft, cmap = 'gray')\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title('idft')\n",
    "    axs[2].imshow(np.subtract(image, idft), cmap = 'gray')\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title('substract')\n",
    "    fig.show()\n",
    "    \n",
    "idft(kolo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Filtracja obrazu w dziedzinie częstotliwości\n",
    "\n",
    "1. Wczytaj obraz \"lena.bmp\" w skali szarości.\n",
    "Wykonaj transformatę Fouriera.\n",
    "Wykorzystaj stworzony poprzednio kod.\n",
    "Wyświetl obraz oryginalny, amplitudę (w skali logarytmicznej) i fazę.\n",
    "\n",
    "2. Przeprowadź filtrację dolnoprzepustową - usuń górne częstotliwości.\n",
    "Dla F-obrazu po operacji przesunięcia (`fftshift`) niskie częstotliwości leżą w jego centrum.\n",
    "\n",
    "3. Na początku stwórz filtr \"kołowy\", dolnoprzepustowy.\n",
    "Należy wygenerować macierze opisujące przestrzeń w dziedzinie częstotliwości.\n",
    "Ich rozmiar musi być taki sam jak rozmiar przetwarzanego obrazu.\n",
    "        lenaSize = I_Lena.shape\n",
    "        FSpaceRows = 2 * np.fft.fftshift(np.fft.fftfreq(lenaSize[0]))\n",
    "        FSpaceRowsM = np.outer(FSpaceRows, np.ones([1, lenaSize[1]]))\n",
    "        FSpaceCols = 2 * np.fft.fftshift(np.fft.fftfreq(lenaSize[1]))\n",
    "        FSpaceColsM = np.outer(np.ones([1, lenaSize[0]]), FSpaceCols)\n",
    "Powyższy kod wygeneruje dwie znormalizowane macierze częstotliwości: *FSpaceRowsM* i *FSpaceColsM*.\n",
    "Następnie należy wyznaczyć macierz zawierającą \"odległość\" od składowej stałej.\n",
    "        FreqR = np.sqrt(np.square(FSpaceRowsM) + np.square(FSpaceColsM))\n",
    "\n",
    "Uwagi:\n",
    "- funkcja `fftfreq` generuje wektor częstotliwości $[-0.5, 0.5]$ o określonym rozmiarze, przy czym układ wartości jest taki, że najpierw od 0 do 0.5, a potem od -0.5 do 0,\n",
    "- operacja `fftshift` zmienia ten układ na $[-0.5, 0.5]$,\n",
    "- mnożenie przez 2 ustala ostatecznie zakres na $[-1, 1]$,\n",
    "- operacja `outer` to tzw. iloczyn zewnętrzy dwóch wektorów, w naszym przypadku powoduje, że wektor pionowy lub poziomy jest \"powielany\" odpowiednią liczbę razy.   \n",
    "- sugeruje się, aby przyglądnąć się jak wygląda macierz `FreqR` - czy to w debugerze, czy poprzez wizualizację.\n",
    "\n",
    "4. Teraz należy wybrać interesujący zakres.\n",
    "Tu można zdefiniować typ filtru (dolno, górno, pasmowoprzepustowy).\n",
    "\n",
    "        FilterF = FreqR <= 0.1\n",
    "\n",
    "Filtr należy zwizualizować:\n",
    "\n",
    "        figFilter = plt.figure()\n",
    "        axsFilter = figFilter.add_subplot(projection='3d')\n",
    "        axsFilter.plot_surface(FSpaceRowsM, FSpaceColsM, FilterF, rstride=1, cstride=1, cmap=plt.get_cmap('gray'), linewidth=0)\n",
    "        figFilter.show()\n",
    "\n",
    "4. Wykonaj właściwą filtrację, czyli mnożenie F-obrazu przez filtr FilterF.\n",
    "Trzeba pamiętać, że F-obraz ma 2 kanały (rzeczywisty i urojony).\n",
    "By mnożenie było możliwe należy więc powielić filtr również na 2 kanały.\n",
    "\n",
    "        FilterF3 = np.repeat(FilterF[:, :, np.newaxis], 2, axis=2)\n",
    "\n",
    "5. Wykonaj operację odwrotnego przesunięcia i odwrotnej transformaty.\n",
    "Oblicz wartość bezwzględną wyniku.\n",
    "Wykorzystaj funkcję `cv2.magnitude`.\n",
    "Pierwszym argumentem jest część rzeczywista.\n",
    "Drugim argumentem jest część urojona.\n",
    "Wynik wyświetl.\n",
    "\n",
    "6. Poeksperymentuj z rozmiarem filtru (promieniem).\n",
    "Zaimplementuj filtr górnoprzepustowy (zmiana znaku przy warunku na odległość) oraz pasmowoprzepustowy (dwa warunki na promień połączone operatorem AND '&' ).\n",
    "Wykonaj co najmniej trzy filtry i wyświetl wyniki.\n",
    "\n",
    "7. W ten sposób zaimplementowana filtracja wprowadza pewne artefakty w postaci \"pierścieni\" wokół krawędzi.\n",
    "Zapobiec temu zjawisku można poprzez odpowiednie \"modelowanie\" filtra.\n",
    "W tym celu wykorzystać należy okna, np. Hamminga, Hanninga, Chebysheva (znane z przetwarzania sygnałów 1D).\n",
    "Zagadnienie to jest tematem zadania domowego do tego ćwiczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Zadanie 4 - filtracja\n"
    }
   },
   "outputs": [],
   "source": [
    "lena = cv2.imread('lena.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "plt.gray()\n",
    "\n",
    "dft(lena)\n",
    "lenaSize = lena.shape\n",
    "FSpaceRows = 2 * np.fft.fftshift(np.fft.fftfreq(lenaSize[0]))\n",
    "FSpaceRowsM = np.outer(FSpaceRows, np.ones([1, lenaSize[1]]))\n",
    "FSpaceCols = 2 * np.fft.fftshift(np.fft.fftfreq(lenaSize[1]))\n",
    "FSpaceColsM = np.outer(np.ones([1, lenaSize[0]]), FSpaceCols)\n",
    "\n",
    "FreqR = np.sqrt(np.square(FSpaceRowsM) + np.square(FSpaceColsM))\n",
    "FilterF = FreqR <= 0.1\n",
    "\n",
    "figFilter = plt.figure()\n",
    "axsFilter = figFilter.add_subplot(projection='3d')\n",
    "axsFilter.plot_surface(FSpaceRowsM, FSpaceColsM, FilterF, rstride=1, cstride=1, cmap=plt.get_cmap('gray'), linewidth=0)\n",
    "figFilter.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_filter= np.repeat(FilterF[:, :, np.newaxis], 2, axis=2)\n",
    "\n",
    "lena_dft = cv2.dft(np.float32(lena), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "dft_shift = np.fft.fftshift(lena_dft)\n",
    "filterd = dft_shift * lp_filter\n",
    "idft_shift = np.fft.ifftshift(filterd)\n",
    "idft_lena1 = cv2.idft(idft_shift)\n",
    "idft_lena1 = cv2.magnitude(abs(idft_lena1[:,:,0]), abs(idft_lena1[:,:,1]))\n",
    "\n",
    "\n",
    "hp_filter_ = FreqR >= 0.2\n",
    "hp_filter = np.repeat(hp_filter_[:, :, np.newaxis], 2, axis=2)\n",
    "filterd = dft_shift * hp_filter\n",
    "idft_shift = np.fft.ifftshift(filterd)\n",
    "idft_lena2 = cv2.idft(idft_shift)\n",
    "idft_lena2 = cv2.magnitude(abs(idft_lena2[:,:,0]), abs(idft_lena2[:,:,1]))\n",
    "\n",
    "\n",
    "p_filer_ = ((FreqR >= 0.2) & (FreqR <= 0.4))\n",
    "p_filer = np.repeat(p_filer_[:, :, np.newaxis], 2, axis=2)\n",
    "filterd = dft_shift * p_filer\n",
    "idft_shift = np.fft.ifftshift(filterd)\n",
    "idft_lena3 = cv2.idft(idft_shift)\n",
    "idft_lena3 = cv2.magnitude(abs(idft_lena3[:,:,0]), abs(idft_lena3[:,:,1]))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,15))\n",
    "axs[0].imshow(idft_lena1, cmap = 'gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('dolnoprzepustowy')\n",
    "axs[1].imshow(idft_lena2, cmap = 'gray')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('gornoprzepustowy')\n",
    "axs[2].imshow(idft_lena2, cmap = 'gray')\n",
    "axs[2].axis('off')\n",
    "axs[2].set_title('pasmoprzepustowy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementacja wyszukiwania wzorca za pomocą FFT\n",
    "\n",
    "1. Wczytaj w skali szarości i wyświetl obrazy *literki.bmp* i *wzorA.bmp*.\n",
    "\n",
    "2. Wyznacz transformatę Fouriera obrazu *literki.bmp*.\n",
    "\n",
    "3. Obróć drugi obraz o $180^\\circ$.\n",
    "Zastosuj funkcję `np.rot90`.\n",
    "Pierwszym argumentem jest obracana macierz, a drugim liczba obrotów o $90^\\circ$.\n",
    "\n",
    "4. Należy wyznaczyć transformatę Fouriera obróconego obrazu w taki sposób, żeby miała ona taki sam rozmiar jak pierwszy obraz.\n",
    "W tym celu należy zastosować *Zero Padding*.\n",
    "Operacja ta polega na uzupełnieniu obrazu zerami do oczekiwanego rozmiaru.\n",
    "Uzupełnij obraz zerami z **prawej** strony i z **dołu**.\n",
    "W tym celu należy wykorzystać funkcję `cv2.copyMakeBorder`.\n",
    "    - Pierwszym argumentem jest obraz wejściowy.\n",
    "    - Drugim argumentem jest liczba wierszy u góry.\n",
    "    - Trzecim argumentem jest liczba wierszy u dołu.\n",
    "    - Czwartym argumentem jest liczba kolumn z lewej.\n",
    "    - Piątym argumentem jest liczba kolumn z prawej.\n",
    "    - Szóstym argumentem jest flaga typu wypełnienia.\n",
    "    Dla stałej wartości podaj `cv2.BORDER_CONSTANT`.\n",
    "    - Siódmym argementem jest wartość pikseli w ramce.\n",
    "    Przekaż `value=0`.\n",
    "\n",
    "5. Wyznacz transformatę Fouriera obrazu stworzonego w poprzednim punkcie.\n",
    "\n",
    "6. Wyniki obu transformat należy przekonwertować do liczb zespolonych.\n",
    "Obecnie jest to dwukanałowa macierz.\n",
    "Pierwszy kanał odpowiada za część rzeczywistą.\n",
    "Drugi kanał odpowiada za część urojoną.\n",
    "Aby to osiągnąć wystarczy wykonać działanie:\n",
    "        Complex = Real + Imag * 1j\n",
    "\n",
    "7. Przemnóż ze sobą zespolone wyniki transformat.\n",
    "\n",
    "8. Wynik należy powrotnie przekształcić do dwukanałowej macierzy.\n",
    "Aby to zrobić wykonaj operację:\n",
    "        CompMat = cv2.merge([np.real(Complex), np.imag(Complex)])\n",
    "\n",
    "9. Wykonaj odwrotną transformatę Fouriera.\n",
    "Dodaj flagę `flags=cv2.DFT_COMPLEX_INPUT`.\n",
    "\n",
    "10. Oblicz wartość bezwzględną wyniku.\n",
    "\n",
    "11. Wykonaj morfologiczną operację **Top-Hat**, by znaleźć maksima lokalne.\n",
    "Operacja ta zostanie dokładnej wyjaśniona w jednym z kolejnych ćwiczeń.\n",
    "W tym celu wykorzystaj operację:\n",
    "        cv2.morphologyEx(correlation, cv2.MORPH_TOPHAT, np.ones((3, 3), np.uint8))\n",
    "\n",
    "12. Wyświetl obok siebie obraz wejściowy i wynik wykonanych operacji.\n",
    "Czy możesz wskazać położenie wzoru na podstawie drugiego obrazu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Zadanie 4 - wyszukiwanie wzorca\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"literki.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/literki.bmp\n",
    "\n",
    "if not os.path.exists(\"wzorA.bmp\") :\n",
    "    !wget--no-check-certificate https://raw.githubusercontent.com/vision-agh/poc_sw/master/08_Fourier/wzorA.bmp\n",
    "wzorA = cv2.imread('wzorA.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "literki = cv2.imread('literki.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "literki_dft = cv2.dft(np.float32(literki), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "wzorA_rot = np.rot90(wzorA,2)\n",
    "\n",
    "l_width, l_height = literki.shape\n",
    "w_width, w_height = wzorA.shape\n",
    "\n",
    "cpy_wzor = cv2.copyMakeBorder(wzorA_rot, 0, l_width - w_width, 0, l_height - w_height, cv2.BORDER_CONSTANT, value=0)\n",
    "wzorA_dft = cv2.dft(np.float32(cpy_wzor), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "\n",
    "cmplx_wzor = np.fft.fftshift(wzorA_dft[:, :, 0]) + np.fft.fftshift(wzorA_dft[:, :, 1]) * 1j\n",
    "cmplx_lit = np.fft.fftshift(literki_dft[:, :, 0]) + np.fft.fftshift(literki_dft[:, :, 1]) * 1j\n",
    "\n",
    "cmplx_mul = cmplx_wzor*cmplx_lit\n",
    "CompMat = cv2.merge([np.real(cmplx_mul), np.imag(cmplx_mul)])\n",
    "idft = abs(cv2.idft(CompMat, flags=cv2.DFT_COMPLEX_INPUT))\n",
    "idft = cv2.magnitude(idft[:,:,0], idft[:,:,1])\n",
    "cv2.morphologyEx(idft, cv2.MORPH_TOPHAT, np.ones((3, 3), np.uint8))\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,15))\n",
    "axs[0].imshow(wzorA, cmap = 'gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('wzor A')\n",
    "axs[1].imshow(literki, cmap = 'gray')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('literki')\n",
    "axs[2].imshow(idft, cmap = 'gray')\n",
    "axs[2].axis('off')\n",
    "axs[2].set_title('idft')\n",
    "fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
